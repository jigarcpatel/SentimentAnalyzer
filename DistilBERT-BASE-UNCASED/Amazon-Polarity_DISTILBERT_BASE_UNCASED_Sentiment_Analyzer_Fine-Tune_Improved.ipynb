{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11063f01-9364-4d07-aba7-ce3edeb06a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.5.0.dev20240620)\n",
      "Requirement already satisfied: torchvision in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (0.20.0.dev20240620)\n",
      "Requirement already satisfied: torchaudio in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.4.0.dev20240620)\n",
      "Requirement already satisfied: transformers in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: matplotlib in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (3.9.0)\n",
      "Requirement already satisfied: filelock in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: numpy in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Installation of Required Libraries\n",
    "!pip install torch torchvision torchaudio transformers datasets scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c7732c-b175-4b8d-9551-4fdfca8ad878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"]=\"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"]=\"0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c58e9e-f4cd-4af1-9abc-3e5787eb167c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2ece2f6284469995601ed9e66d807c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2520000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b0fa19424f49eb95e442680565e99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e83e7b3a2e94c5992de1dde2b1bff26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37e358b572f456ca46f10b16c7bb5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41311' max='236250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 41311/236250 14:24:52 < 68:01:23, 0.80 it/s, Epoch 0.52/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# execute following optimised code later [this is latest code written by chatGPT] 24 JUNE 6 PM\n",
    "\n",
    "# Import necessary libraries\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Load the Amazon Polarity dataset\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "# Split dataset: 15% for training, 5% for testing, 5% for validation, 5% for evaluation\n",
    "split_ratio = {\n",
    "    \"train\": 0.15,\n",
    "    \"test\": 0.05,\n",
    "    \"validation\": 0.05,\n",
    "    \"evaluation\": 0.05\n",
    "}\n",
    "\n",
    "# Create initial split: 30% of data\n",
    "initial_split = dataset['train'].train_test_split(test_size=0.30, seed=42)\n",
    "remaining_data = initial_split['test']\n",
    "\n",
    "# Split remaining data into test, validation, and eval\n",
    "test_val_eval_split = remaining_data.train_test_split(test_size=2/3, seed=42)  # Splits into 10% for further split and 20% for unused\n",
    "test_val_split = test_val_eval_split['train'].train_test_split(test_size=0.5, seed=42)  # Splits 10% into 5% test and 5% validation\n",
    "eval_split = test_val_eval_split['test'].train_test_split(test_size=0.5, seed=42)  # Splits 20% into 10% eval and 10% unused\n",
    "\n",
    "train_dataset = initial_split['train']  # 15% of the original dataset\n",
    "test_dataset = test_val_split['train']  # 5% of the original dataset\n",
    "valid_dataset = test_val_split['test']  # 5% of the original dataset\n",
    "eval_dataset = eval_split['train']  # 5% of the original dataset\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize datasets\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['content'], padding=True, truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "valid_dataset = valid_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "eval_dataset = eval_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "valid_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Load the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    eval_strategy=\"epoch\",     \n",
    "    learning_rate=2e-5,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    num_train_epochs=3,              \n",
    "    weight_decay=0.01,               \n",
    "    warmup_steps=500,                \n",
    "    logging_dir='./logs',            \n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=[],\n",
    "    gradient_accumulation_steps=2,  \n",
    "    disable_tqdm=False,  \n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=valid_dataset,          \n",
    "    tokenizer=tokenizer,                 \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model to Hugging Face Hub\n",
    "trainer.push_to_hub(\"distilbert-base-uncased-amazon-polarity\", use_auth_token=\"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\")\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)\n",
    "\n",
    "# Inference\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load model from Hugging Face Hub\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"jigarcpatel/distilbert-base-uncased-amazon-polarity\")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"jigarcpatel/distilbert-base-uncased-amazon-polarity\")\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Real examples for inference\n",
    "examples = [\n",
    "    \"This product is fantastic! I highly recommend it.\",\n",
    "    \"I had a terrible experience with this service.\"\n",
    "]\n",
    "\n",
    "# Predict sentiments\n",
    "predictions = classifier(examples)\n",
    "for example, prediction in zip(examples, predictions):\n",
    "    print(f\"Text: {example}\\nSentiment: {prediction['label']}, Score: {prediction['score']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00541d28-a909-40cb-aea1-c3020655bff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding)\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Check for MPS availability (for Mac M1/M2)\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "# Initial split: keep 18% of the data\n",
    "initial_split = dataset['train'].train_test_split(test_size=0.18, seed=42)\n",
    "\n",
    "# Split the 18% data into train (10%), test (2%), validation (3%), and eval (3%)\n",
    "train_valid_test_split = initial_split['test'].train_test_split(test_size=0.4444, seed=42)  # Splits the 18% into 8% (test + validation + eval) and 10% train\n",
    "valid_test_eval_split = train_valid_test_split['test'].train_test_split(test_size=0.4286, seed=42)  # Splits 8% into 3% valid and 5% (test + eval)\n",
    "test_eval_split = valid_test_eval_split['test'].train_test_split(test_size=0.6, seed=42)  # Splits 5% into 2% test and 3% eval\n",
    "\n",
    "train_dataset = train_valid_test_split['train']  # This is 10% of the original dataset\n",
    "valid_dataset = valid_test_eval_split['train']  # This is 3% of the original dataset\n",
    "test_dataset = test_eval_split['train']  # This is 2% of the original dataset\n",
    "eval_dataset = test_eval_split['test']  # This is 3% of the original dataset\n",
    "\n",
    "# Printing the sizes of the splits\n",
    "print(f\"Original dataset sizes: {dataset}\")\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")\n",
    "\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"  # Smaller and efficient model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"content\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,  # Increased batch size\n",
    "    per_device_eval_batch_size=16,   # Increased batch size\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    warmup_steps=500,\n",
    "    gradient_accumulation_steps=2,  # Reduced gradient accumulation steps\n",
    "    #fp16=True,  # Use mixed precision training\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model to Hugging Face Hub\n",
    "login(token='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')\n",
    "trainer.push_to_hub(\"jigarcpatel/distilbert-base-uncased-amazon-polarity\")\n",
    "\n",
    "# Evaluate on test dataset\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix\\nAccuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Display some false positives and false negatives\n",
    "false_positives = np.where((preds == 1) & (labels == 0))[0]\n",
    "false_negatives = np.where((preds == 0) & (labels == 1))[0]\n",
    "\n",
    "print(\"Sample False Positives:\")\n",
    "for idx in false_positives[:3]:\n",
    "    print(f\"Review: {test_dataset[idx]['content']}\\nPredicted: {preds[idx]}, Actual: {labels[idx]}\\n\")\n",
    "\n",
    "print(\"Sample False Negatives:\")\n",
    "for idx in false_negatives[:3]:\n",
    "    print(f\"Review: {test_dataset[idx]['content']}\\nPredicted: {preds[idx]}, Actual: {labels[idx]}\\n\")\n",
    "\n",
    "# Inference function\n",
    "def infer(text):\n",
    "    # Load model from Hugging Face Hub\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"jigarcpatel/distilbert-base-uncased-amazon-polarity\").to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"jigarcpatel/distilbert-base-uncased-amazon-polarity\")\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    return torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "# Sample inference\n",
    "sample_texts = [\n",
    "    \"This product is amazing! I love it and would highly recommend it to anyone.\",\n",
    "    \"Terrible service. I am very disappointed and will not be coming back.\"\n",
    "]\n",
    "\n",
    "for text in sample_texts:\n",
    "    prediction = infer(text)\n",
    "    print(f\"Text: {text}\\nPrediction: {'Positive' if prediction == 1 else 'Negative'}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c1585-f619-47a1-8f31-43529eb05a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from huggingface hub and run the inference \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Step 1: Define the model and tokenizer names\n",
    "model_name = \"jigarcpatel/distilbert-base-uncased-amazon-polarity\"\n",
    "tokenizer_name = \"jigarcpatel/distilbert-base-uncased-amazon-polarity\"\n",
    "\n",
    "# Step 2: Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# Step 3: Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Step 4: Define a function for inference\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    return predictions.item()\n",
    "\n",
    "# Step 5: Example usage of the predict_sentiment function\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"This movie was really great! I enjoyed every bit of it.\"\n",
    "    sentiment = predict_sentiment(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Sentiment: {'Positive' if sentiment == 1 else 'Negative'}\")\n",
    "\n",
    "# Step 6: Example usage of the predict_sentiment function for negative case possily\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"Dog is barking anyone who shows up at the door.\"\n",
    "    sentiment = predict_sentiment(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Sentiment: {'Positive' if sentiment == 1 else 'Negative'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce1356-6563-48b0-a8be-37b472543287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eleven",
   "language": "python",
   "name": "eleven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
