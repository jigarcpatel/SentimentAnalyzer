{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f510e654-2c2e-4b7c-880a-71a6a5fce435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, starting...\n",
      "Requirement already satisfied: transformers in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: torch in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.5.0.dev20240620)\n",
      "Requirement already satisfied: tensorflow-macos in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-metal in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: filelock in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow-macos) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow==2.16.1->tensorflow-macos) (0.37.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorflow-metal) (0.43.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: rich in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.1->tensorflow-macos) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.1->tensorflow-macos) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.1->tensorflow-macos) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->tensorflow-macos) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->tensorflow-macos) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->tensorflow-macos) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->tensorflow-macos) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->tensorflow-macos) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1->tensorflow-macos) (0.1.2)\n",
      "Library installed.\n",
      "MPS backend is available!\n",
      "Devices:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, starting...\")\n",
    "# Installation of Required Libraries\n",
    "!pip install transformers datasets torch tensorflow-macos tensorflow-metal \n",
    "\n",
    "import torch\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"Library installed.\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    print(\"MPS backend is not available.\")\n",
    "\n",
    "devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Devices: \", devices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538087e3-d6f7-4e53-ab77-17069ff2f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"]=\"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"]=\"0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450688bf-ae04-40f2-b5aa-00b169d87a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available and set the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30ca91-18da-47be-8962-0c3463b7d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3bd2e51b344a9aa0762717ddff3252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a317c6992a44f61a7e097cdd08d3a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e1567fd3d147b8a4f23994d17051d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/51/ygbp8z0j7r57_z285c01c66w0000gn/T/ipykernel_56946/731204973.py:43: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_metric = load_metric(\"accuracy\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1002' max='2109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1002/2109 14:30:39 < 16:03:49, 0.02 it/s, Epoch 1.42/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2104995.328000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.507200</td>\n",
       "      <td>0.341364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, load_metric, DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Ensure MPS is used on a MacBook M3 if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the IMDB dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_val_split = dataset['train'].train_test_split(test_size=0.1)\n",
    "test_split = dataset['test'].train_test_split(test_size=0.1)\n",
    "train_data, val_data = train_val_split['train'], train_val_split['test']\n",
    "test_data = test_split['test']\n",
    "\n",
    "# Create a DatasetDict to work with the Trainer API\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_data,\n",
    "    'validation': val_data,\n",
    "    'test': test_data\n",
    "})\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\")\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Define metrics\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train and evaluate the model\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the model to the Hugging Face Hub\n",
    "model.push_to_hub(\"finetuned-roberta-large-imdb\")\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(tokenized_datasets[\"test\"][\"labels\"], preds)\n",
    "plot_confusion_matrix(cm, classes=[\"Negative\", \"Positive\"])\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy, precision, recall, f1 score\n",
    "accuracy = accuracy_score(tokenized_datasets[\"test\"][\"labels\"], preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(tokenized_datasets[\"test\"][\"labels\"], preds, average='weighted')\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Print few sample false positives and false negatives\n",
    "false_positives = np.where((preds == 1) & (tokenized_datasets[\"test\"][\"labels\"] == 0))[0]\n",
    "false_negatives = np.where((preds == 0) & (tokenized_datasets[\"test\"][\"labels\"] == 1))[0]\n",
    "\n",
    "print(\"Sample False Positives:\")\n",
    "for idx in false_positives[:5]:\n",
    "    print(tokenized_datasets[\"test\"][idx])\n",
    "\n",
    "print(\"Sample False Negatives:\")\n",
    "for idx in false_negatives[:5]:\n",
    "    print(tokenized_datasets[\"test\"][idx])\n",
    "\n",
    "# Inference function\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\"\n",
    "\n",
    "# Download model for inference\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"jigarcpatel/finetuned-roberta-large-imdb\").to(device)\n",
    "\n",
    "# Sample inference\n",
    "texts = [\"This movie is fantastic!\", \"I hated every moment of this film.\"]\n",
    "for text in texts:\n",
    "    print(f\"Text: {text} | Sentiment: {predict(text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f0580-94d3-47a0-8772-fe3eb2f9d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eleven",
   "language": "python",
   "name": "eleven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
