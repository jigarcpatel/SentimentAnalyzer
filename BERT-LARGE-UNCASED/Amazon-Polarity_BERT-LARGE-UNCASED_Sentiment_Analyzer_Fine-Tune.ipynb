{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11063f01-9364-4d07-aba7-ce3edeb06a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.5.0.dev20240620)\n",
      "Requirement already satisfied: torchvision in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (0.20.0.dev20240620)\n",
      "Requirement already satisfied: torchaudio in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.4.0.dev20240620)\n",
      "Requirement already satisfied: transformers in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: matplotlib in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (3.9.0)\n",
      "Requirement already satisfied: filelock in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: numpy in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Installation of Required Libraries\n",
    "!pip install torch torchvision torchaudio transformers datasets scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c7732c-b175-4b8d-9551-4fdfca8ad878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"]=\"1\"\n",
    "#os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"]=\"0.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00541d28-a909-40cb-aea1-c3020655bff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/jigarpatel/.pyenv/versions/eleven/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2229' max='33750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2229/33750 9:11:47 < 130:10:02, 0.07 it/s, Epoch 0.20/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 76\u001b[0m\n\u001b[1;32m     67\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     68\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     69\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Save the model and tokenizer\u001b[39;00m\n\u001b[1;32m     79\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine-tuned-bert-large-uncased-amazon-polarity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/eleven/lib/python3.11/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/eleven/lib/python3.11/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.pyenv/versions/eleven/lib/python3.11/site-packages/transformers/trainer.py:3250\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.pyenv/versions/eleven/lib/python3.11/site-packages/accelerate/accelerator.py:2134\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2134\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/eleven/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/eleven/lib/python3.11/site-packages/torch/autograd/__init__.py:288\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/eleven/lib/python3.11/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fine-Tune the Model:\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load the IMDB dataset\n",
    "#dataset = load_dataset(\"imdb\")\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "\n",
    "traintest_ = tokenized_datasets[\"test\"].train_test_split(test_size=0.1)\n",
    "\n",
    "train_dataset = traintest_[\"train\"]\n",
    "test_dataset = traintest_[\"test\"]\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    disable_tqdm=False,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# Define compute metrics function\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\"binary\")\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model_path = \"./fine-tuned-bert-large-uncased-amazon-polarity\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "# Push model to Hugging Face Hub\n",
    "trainer.push_to_hub(\"fine-tuned-bert-large-uncased-amazon-polarity\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8df6b-6feb-4850-b1fe-2cd3887b0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model for Inference:\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    return torch.argmax(probs).item()\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"I absolutely loved this movie! The performances were stellar.\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96a69c-9180-4a7d-a9af-2e7d8f138d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if MPS is available and set the device\n",
    "device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f32d4b-c2d6-4fe7-af3b-9210bc85d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference\n",
    "sample_text = \"This is ok but could have been lot better\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"dog is barking to someone who shows up at the door\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"you are fucking awesome\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"you are fucking terrible\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"redical policies to end the failure of community care\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"why was schizophrenic freed to kill my father\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"wicked nurse suspected of over 30 sabotage incidents\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")\n",
    "\n",
    "# Test inference\n",
    "sample_text = \"fake doctor gave two injections to patients\"\n",
    "print(\"Sentiment:\", \"Positive\" if predict_sentiment(sample_text) == 1 else \"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436574d2-8ad9-48f7-8893-9967cf1c1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your fine-tuned model and tokenizer\n",
    "model_path = \"./fine-tuned-bert-large-uncased-amazon-polarity\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Assuming `test_dataset` is your dataset in a compatible format\n",
    "# It should be a list of dictionaries with \"text\" and \"label\" keys\n",
    "\n",
    "# Define a function to get predictions\n",
    "def get_predictions(model, tokenizer, dataset):\n",
    "    predictions, true_labels = [], []\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    for i in range(len(dataset)):\n",
    "        inputs = tokenizer(dataset[i][\"text\"], return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        predictions.append(torch.argmax(probs).item())\n",
    "        true_labels.append(dataset[i][\"label\"])\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Assuming `test_dataset` is a list of dictionaries with 'text' and 'label' keys\n",
    "test_dataset = [\n",
    "    {\"text\": \"This movie was great!\", \"label\": 1},\n",
    "    {\"text\": \"I did not like this movie.\", \"label\": 0},\n",
    "    {\"text\": \"This movie is awesome.\", \"label\": 1},\n",
    "    {\"text\": \"Food poisoning reaches epidemic level.\", \"label\": 0},\n",
    "    {\"text\": \"iPhone 11 heating problem after 15.4.1 upgrade.\", \"label\": 0},\n",
    "    {\"text\": \"Depressed mood during pet bereavement is common\", \"label\": 0},\n",
    "    {\"text\": \"What to Eat After a Workout for Nutrition and Muscle Recovery\", \"label\": 1},\n",
    "    {\"text\": \"my iPhone X began to heat up even for doing a little stuff in the really light apps much more faster than the iOS 13.7 hence please share with me if you've been dealing with the same issue.\", \"label\": 0},\n",
    "    {\"text\": \"the battery does not drain faster and it seems ok\", \"label\": 1},\n",
    "    # Add more examples here\n",
    "]\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = get_predictions(model, tokenizer, test_dataset)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions, labels=[0, 1])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1cfbe-f4d2-4ef9-8dd0-4e57e5d61193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark with SST-2 dataset\n",
    "\n",
    "# Install necessary libraries\n",
    "# !pip install transformers datasets scikit-learn torch\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the SST-2 dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_path = \"./fine-tuned-bert-large-uncased-amazon-polarity\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Create DataLoader for evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "eval_dataloader = DataLoader(encoded_dataset['validation'], batch_size=8)\n",
    "\n",
    "# Function to get predictions and true labels\n",
    "def get_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    for batch in dataloader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "        labels = batch['label'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            pred_labels = torch.argmax(probs, dim=-1)\n",
    "            predictions.extend(pred_labels.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = get_predictions(model, eval_dataloader)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fd10a-bef8-4dee-a994-6c3305553ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark with SST-2 dataset\n",
    "# print all the false positive cases separately and all the false negative cases separately\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the SST-2 dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_path = \"./fine-tuned-bert-large-uncased-amazon-polarity\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label', 'sentence'])\n",
    "\n",
    "# Create DataLoader for evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "eval_dataloader = DataLoader(encoded_dataset['validation'], batch_size=8)\n",
    "\n",
    "# Function to get predictions and true labels along with their sentences\n",
    "def get_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions, true_labels, sentences = [], [], []\n",
    "    for batch in dataloader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "        labels = batch['label'].to(device)\n",
    "        batch_sentences = batch['sentence']\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            pred_labels = torch.argmax(probs, dim=-1)\n",
    "            predictions.extend(pred_labels.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            sentences.extend(batch_sentences)\n",
    "    return predictions, true_labels, sentences\n",
    "\n",
    "# Get predictions, true labels and sentences\n",
    "predictions, true_labels, sentences = get_predictions(model, eval_dataloader)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print false positives and false negatives\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for sentence, true_label, pred_label in zip(sentences, true_labels, predictions):\n",
    "    if true_label == 0 and pred_label == 1:\n",
    "        false_positives.append(sentence)\n",
    "    elif true_label == 1 and pred_label == 0:\n",
    "        false_negatives.append(sentence)\n",
    "\n",
    "print(\"\\nFalse Positives:\")\n",
    "for sentence in false_positives:\n",
    "    print(sentence)\n",
    "\n",
    "print(\"\\nFalse Negatives:\")\n",
    "for sentence in false_negatives:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e7f4e-c6a8-4a9f-b006-29d77074ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the Amazon Review dataset\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_path = \"./fine-tuned-bert-large-uncased-amazon-polarity\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Create a subset of the first 100 examples\n",
    "subset_dataset = Subset(encoded_dataset['test'], range(10000))\n",
    "\n",
    "# Create DataLoader for evaluation\n",
    "eval_dataloader = DataLoader(subset_dataset, batch_size=16)\n",
    "\n",
    "# Function to get predictions and true labels\n",
    "def get_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    num_batches = len(dataloader)\n",
    "    for batch in tqdm(dataloader, total=num_batches, desc=\"Evaluating\"):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "        labels = batch['label'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            pred_labels = torch.argmax(probs, dim=-1)\n",
    "            predictions.extend(pred_labels.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = get_predictions(model, eval_dataloader)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Identify false positives and false negatives\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for i in range(len(true_labels)):\n",
    "    if true_labels[i] != predictions[i]:\n",
    "        if predictions[i] == 1:  # Predicted positive, actual negative (False Positive)\n",
    "            false_positives.append((i, predictions[i], true_labels[i], dataset['test'][i]['content']))\n",
    "        else:  # Predicted negative, actual positive (False Negative)\n",
    "            false_negatives.append((i, predictions[i], true_labels[i], dataset['test'][i]['content']))\n",
    "\n",
    "# Print false positives\n",
    "print(\"\\nFalse Positives:\")\n",
    "for fp in false_positives:\n",
    "    print(f\"Index: {fp[0]}, Predicted Label: {fp[1]}, Actual Label: {fp[2]}\")\n",
    "    print(f\"Review: {fp[3]}\\n\")\n",
    "\n",
    "# Print false negatives\n",
    "print(\"\\nFalse Negatives:\")\n",
    "for fn in false_negatives:\n",
    "    print(f\"Index: {fn[0]}, Predicted Label: {fn[1]}, Actual Label: {fn[2]}\")\n",
    "    print(f\"Review: {fn[3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c1585-f619-47a1-8f31-43529eb05a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from huggingface hub and run the inference \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Step 1: Define the model and tokenizer names\n",
    "model_name = \"jigarcpatel/fine-tuned-bert-large-uncased-amazon-polarity\"\n",
    "tokenizer_name = \"jigarcpatel/fine-tuned-bert-large-uncased-amazon-polarity\"\n",
    "\n",
    "# Step 2: Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# Step 3: Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Step 4: Define a function for inference\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    return predictions.item()\n",
    "\n",
    "# Step 5: Example usage of the predict_sentiment function\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"This movie was really great! I enjoyed every bit of it.\"\n",
    "    sentiment = predict_sentiment(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Sentiment: {'Positive' if sentiment == 1 else 'Negative'}\")\n",
    "\n",
    "# Step 6: Example usage of the predict_sentiment function for negative case possily\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"Dog is barking anyone who shows up at the door.\"\n",
    "    sentiment = predict_sentiment(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Sentiment: {'Positive' if sentiment == 1 else 'Negative'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce1356-6563-48b0-a8be-37b472543287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eleven",
   "language": "python",
   "name": "eleven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
